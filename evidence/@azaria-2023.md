# The Internal State of an LLM Knows When its Lying

**Authors:** A. Azaria, Tom M. Mitchell
**Year:** 2023
**DOI:** 10.18653/v1/2023.findings-emnlp.68
**Citation Count:** 431

## Evidence Items

- SAPLMA achieved 71% to 83% accuracy in binary truthfulness classification across different LLM base models, significantly outperforming baseline approaches #evd-candidate ^evd-001
	- **What**: Classification accuracy scores ranging from 71% to 83% for identifying true versus false statements
	- **How**: Training feedforward neural network classifiers on LLM hidden layer activations using cross-topic validation (training on 5 topics, testing on held-out topic)
	- **Who**: 6,084 sentences across six topics (Cities, Inventions, Chemical Elements, Animals, Companies, Scientific Facts) tested on Facebook OPT-6.7b and LLAMA2-7b models
- Few-shot prompting achieved only up to 56% accuracy on the same truthfulness classification task, performing barely above random chance #evd-candidate ^evd-002
	- **What**: Maximum accuracy of 56% for few-shot learning approaches (3-shot and 5-shot), close to random baseline of 50%
	- **How**: Direct prompting of OPT-6.7b model with few examples to classify statements as true or false
	- **Who**: Same 6,084 sentence dataset across six factual topics using OPT-6.7b model
- LLAMA2-7b consistently outperformed OPT-6.7b across all topics, achieving 70% to 90% accuracy compared to 60% to 80% accuracy respectively #evd-candidate ^evd-003
	- **What**: Comparative accuracy scores showing 10-percentage point improvement range for LLAMA2-7b over OPT-6.7b
	- **How**: Same SAPLMA methodology applied to both models with identical training/testing procedures and optimal threshold selection
	- **Who**: Cross-validation testing on the six-topic truthfulness dataset comparing two 32-layer LLMs of similar parameter counts
- BERT-based classification performed at near-random levels (approximately 50% accuracy), demonstrating inferior performance compared to LLM-based approaches #evd-candidate ^evd-004
	- **What**: BERT classification accuracy around 50%, statistically indistinguishable from random guessing
	- **How**: Training identical feedforward neural network architecture on BERT sentence embeddings instead of LLM hidden states
	- **Who**: Same 6,084 sentence truthfulness dataset used for SAPLMA comparison
- Performance varied significantly by topic domain, with Cities and Companies topics achieving higher accuracy than other domains #evd-candidate ^evd-005
	- **What**: Topic-specific accuracy variations, with Cities and Companies showing superior performance compared to Chemical Elements, Animals, Inventions, and Scientific Facts
	- **How**: Cross-topic validation design allowing measurement of domain-specific performance differences
	- **Who**: Six distinct factual domains within the 6,084 sentence dataset, ranging from 612 to 1,458 sentences per topic
- Statistical significance was established for layer-specific performance differences, with optimal layers varying by model architecture #evd-candidate ^evd-006
	- **What**: Statistically significant performance differences between layers (p < 0.05), with 20th layer optimal for OPT-6.7b and middle layers for LLAMA2-7b
	- **How**: Two-tailed student t-tests comparing accuracy across different hidden layers within each 32-layer model
	- **Who**: Layer-wise analysis conducted on both OPT-6.7b and LLAMA2-7b models using the full truthfulness dataset
- LLM-generated sentences showed degraded classification performance compared to externally-sourced statements, suggesting increased subjectivity in model-generated content #evd-candidate ^evd-007
	- **What**: Lower classification accuracy on LLM-generated sentences compared to human-curated true/false statements
	- **How**: Separate evaluation on statements generated by the LLM itself, maintaining 50% true/50% false distribution
	- **Who**: OPT-6.7b generated sentences compared against the original curated dataset across the same six topical domains
- Higher classification thresholds improved SAPLMA performance, supporting conservative approaches to mitigate false information propagation #evd-candidate ^evd-008
	- **What**: Improved accuracy scores when using optimal thresholds derived from validation sets rather than default 0.5 threshold
	- **How**: Threshold optimization on validation data followed by application to test sets, with justification based on asymmetric error costs
	- **Who**: Threshold optimization applied across all six topics in the truthfulness dataset for both LLM models tested
